{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5eb94d5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from sklearn.feature_extraction.text import ENGLISH_STOP_WORDS\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e0377092",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>Liked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Wow... Loved this place.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Crust is not good.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Not tasty and the texture was just nasty.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Stopped by during the late May bank holiday of...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The selection on the menu was great and so wer...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>I think food should have flavor and texture an...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>Appetite instantly gone.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>Overall I was not impressed and would not go b...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>The whole experience was underwhelming, and I ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>Then, as if I hadn't wasted enough of my life ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Review  Liked\n",
       "0                             Wow... Loved this place.      1\n",
       "1                                   Crust is not good.      0\n",
       "2            Not tasty and the texture was just nasty.      0\n",
       "3    Stopped by during the late May bank holiday of...      1\n",
       "4    The selection on the menu was great and so wer...      1\n",
       "..                                                 ...    ...\n",
       "995  I think food should have flavor and texture an...      0\n",
       "996                           Appetite instantly gone.      0\n",
       "997  Overall I was not impressed and would not go b...      0\n",
       "998  The whole experience was underwhelming, and I ...      0\n",
       "999  Then, as if I hadn't wasted enough of my life ...      0\n",
       "\n",
       "[1000 rows x 2 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df= pd.read_csv(\"D:/dataset/sentiment/Restaurant_Reviews.txt\", sep=\"\\t\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7cd66f38",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = df['Review'].tolist()\n",
    "target = df['Liked'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5419a722",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus1= list(map(str.lower, corpus))\n",
    "# print(corpus1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8b739a95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wow Loved this place\n"
     ]
    }
   ],
   "source": [
    "def removePunc(doc):\n",
    "    newdoc = re.sub('[^ a-zA-Z\\s]', '', doc)\n",
    "    return newdoc\n",
    "\n",
    "text = \"Wow... Loved this place.\"\n",
    "cleaned_text = removePunc(text)\n",
    "print(cleaned_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a9409c9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus2 = list(map(removePunc, corpus1))\n",
    "# print(corpus2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5dd16e47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "318\n",
      "frozenset({'either', 'serious', 'further', 'thereupon', 'should', 'our', 'even', 'amongst', 'yours', 'some', 'call', 'whence', 'their', 'latterly', 'without', 'perhaps', 'twelve', 'within', 'six', 'too', 'already', 'part', 'sometimes', 'empty', 'thereafter', 'sometime', 'became', 'moreover', 'whether', 'how', 'nor', 'describe', 'due', 'another', 'but', 'of', 'done', 'still', 'amount', 'take', 'why', 'much', 'above', 'whole', 'an', 'around', 'who', 'thick', 'no', 'could', 'hundred', 'indeed', 'us', 'hereafter', 'were', 'please', 'fifteen', 'hers', 'hence', 'others', 'only', 'eleven', 'amoungst', 'by', 'meanwhile', 'however', 'thin', 'my', 'with', 'two', 'until', 'will', 'seem', 'out', 'after', 'most', 'otherwise', 'fill', 'former', 'bill', 'else', 'i', 'upon', 'do', 'these', 'your', 'interest', 'fire', 'whoever', 'five', 'ourselves', 'side', 'or', 'whither', 'and', 'few', 'cannot', 'each', 'thereby', 'those', 'anyway', 'detail', 'on', 'find', 'are', 'many', 'top', 'eight', 'now', 'someone', 'that', 'mine', 'latter', 'herein', 'once', 'front', 'they', 'couldnt', 'yet', 'beside', 'we', 'me', 'give', 'off', 'can', 'onto', 'whereafter', 'he', 'hereby', 'she', 'besides', 'behind', 'about', 'enough', 'forty', 'fifty', 'is', 'any', 'last', 'twenty', 'ever', 'be', 'whenever', 'for', 'again', 'first', 'also', 'both', 'neither', 'at', 'her', 'itself', 'move', 'though', 'everywhere', 'keep', 'then', 'under', 'them', 'him', 'eg', 'three', 'had', 'not', 'being', 'never', 'therefore', 'almost', 'whose', 'such', 'the', 'down', 'although', 'up', 'into', 'less', 'system', 'while', 'nine', 'ie', 'becomes', 'beyond', 'something', 'must', 'found', 'you', 'anywhere', 'when', 'whom', 'least', 'themselves', 'which', 'nothing', 'back', 'ltd', 'bottom', 'get', 'against', 'what', 'become', 'across', 'towards', 'if', 'along', 'nowhere', 'somehow', 'beforehand', 'sixty', 'am', 'nevertheless', 'cant', 'made', 'a', 'as', 'yourself', 'whereas', 'co', 'anyone', 'hasnt', 'here', 'cry', 'mostly', 'thru', 'whereby', 'than', 'four', 'before', 'thus', 'his', 'throughout', 'below', 'own', 'put', 'very', 'one', 'so', 'anyhow', 'have', 'to', 'because', 'go', 'over', 'elsewhere', 'its', 'therein', 'seemed', 'becoming', 'afterwards', 'has', 'wherever', 'per', 'may', 'since', 'wherein', 'always', 'show', 'this', 'through', 'see', 'several', 'every', 'in', 'there', 'inc', 'via', 'it', 'thence', 'ours', 'full', 'during', 'everything', 'well', 'might', 'mill', 'seeming', 'myself', 'hereupon', 're', 'been', 'everyone', 'un', 'where', 'none', 'often', 'sincere', 'formerly', 'toward', 'anything', 'except', 'etc', 'alone', 'con', 'somewhere', 'between', 'from', 'other', 'rather', 'namely', 'among', 'himself', 'whatever', 'ten', 'nobody', 'herself', 'more', 'third', 'same', 'next', 'would', 'de', 'name', 'yourselves', 'together', 'was', 'seems', 'whereupon', 'all', 'noone'})\n"
     ]
    }
   ],
   "source": [
    "#Step-3 remmove stopwords(words having no sentiment) like it, is, was, did, has, have.\n",
    "\n",
    "print(len(ENGLISH_STOP_WORDS))\n",
    "print(ENGLISH_STOP_WORDS)\n",
    "# print(ENGLISH_STOP_WORDS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7ef8637d",
   "metadata": {},
   "outputs": [],
   "source": [
    "spwords = list(ENGLISH_STOP_WORDS)\n",
    "spwords.remove(\"not\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a3489e18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Not tasty texture just nasty. '"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def removespwords(doc):\n",
    "    wordslist= doc.split()\n",
    "    newdoc=\"\"\n",
    "    for word in wordslist:\n",
    "        if word not in spwords:\n",
    "            newdoc= newdoc+word+\" \"\n",
    "    return newdoc\n",
    "\n",
    "removespwords(\"Not tasty and the texture was just nasty.\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "38d24df8",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus3 = list(map(removespwords, corpus2))\n",
    "# print(corpus3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "05daa0a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['absolute', 'absolutely', 'absolutley', ..., 'yum', 'yummy',\n",
       "       'zero'], dtype=object)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv= CountVectorizer()\n",
    "X= cv.fit_transform(corpus3)\n",
    "cv.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "957ec796",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['absolute' 'absolutely' 'absolutley' ... 'yum' 'yummy' 'zero']\n",
      "  (0, 1810)\t1\n",
      "  (0, 930)\t1\n",
      "  (0, 1190)\t1\n",
      "  (1, 358)\t1\n",
      "  (1, 1070)\t1\n",
      "  (1, 661)\t1\n",
      "  (2, 1070)\t1\n",
      "  (2, 1600)\t1\n",
      "  (2, 1612)\t1\n",
      "  (2, 856)\t1\n",
      "  (2, 1048)\t1\n",
      "  (3, 930)\t1\n",
      "  (3, 1540)\t1\n",
      "  (3, 877)\t1\n",
      "  (3, 91)\t1\n",
      "  (3, 758)\t1\n",
      "  (3, 1344)\t1\n",
      "  (3, 1533)\t1\n",
      "  (3, 1301)\t1\n",
      "  (4, 1413)\t1\n",
      "  (4, 995)\t1\n",
      "  (4, 674)\t1\n",
      "  (4, 1234)\t1\n",
      "  (5, 645)\t1\n",
      "  (5, 29)\t1\n",
      "  :\t:\n",
      "  (995, 869)\t1\n",
      "  (996, 660)\t1\n",
      "  (996, 41)\t1\n",
      "  (996, 824)\t1\n",
      "  (997, 1070)\t2\n",
      "  (997, 1112)\t1\n",
      "  (997, 804)\t1\n",
      "  (998, 856)\t1\n",
      "  (998, 1631)\t1\n",
      "  (998, 1621)\t1\n",
      "  (998, 1686)\t1\n",
      "  (998, 533)\t1\n",
      "  (998, 1581)\t1\n",
      "  (998, 1063)\t1\n",
      "  (999, 1631)\t1\n",
      "  (999, 1645)\t1\n",
      "  (999, 1378)\t1\n",
      "  (999, 246)\t1\n",
      "  (999, 897)\t1\n",
      "  (999, 176)\t1\n",
      "  (999, 701)\t1\n",
      "  (999, 1755)\t1\n",
      "  (999, 1222)\t1\n",
      "  (999, 1809)\t1\n",
      "  (999, 463)\t1\n",
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "print(cv.get_feature_names_out())\n",
    "print(X)\n",
    "X1=X.toarray()\n",
    "print(X1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dd0bb7b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\n"
     ]
    }
   ],
   "source": [
    "model= LogisticRegression()\n",
    "model.fit(X, target)\n",
    "print(model.predict(cv.transform(['Wow... Loved this place.'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ea78583c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "model= LogisticRegression()\n",
    "model.fit(X, target)\n",
    "print(model.predict(cv.transform([\"Then, as if I hadn't wasted enough of my life ..\"])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ddc63ea4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter sentiment: nice place\n",
      "[1]\n"
     ]
    }
   ],
   "source": [
    "# prediction\n",
    "\n",
    "sample= input('Enter sentiment: ')\n",
    "sample1= sample.lower()\n",
    "sample2= removePunc(sample1)\n",
    "sample3= removespwords(sample2)\n",
    "# print(sample3)\n",
    "\n",
    "sample4= cv.transform([sample3])\n",
    "review= model.predict(sample4)\n",
    "print(review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2aff5579",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter sentiment: nice place\n",
      "Postive Review\n"
     ]
    }
   ],
   "source": [
    "# prediction\n",
    "\n",
    "sample= input('Enter sentiment: ')\n",
    "sample1= sample.lower()\n",
    "sample2= removePunc(sample1)\n",
    "sample3= removespwords(sample2)\n",
    "# print(sample3)\n",
    "\n",
    "sample4= cv.transform([sample3])\n",
    "review= model.predict(sample4)\n",
    "if review==1:\n",
    "    print(\"Postive Review\")\n",
    "else:\n",
    "    print(\"Negative Review\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21bdcfee",
   "metadata": {},
   "source": [
    "# Whole Code in One Cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c3ef45c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After removing Punctutaions : Wow Loved this place\n",
      "Lentgh of English_stop_Words : 318\n",
      "get_feature_names_out : ['absolute' 'absolutely' 'absolutley' ... 'yum' 'yummy' 'zero']\n",
      "The value of X :   (0, 1810)\t1\n",
      "  (0, 930)\t1\n",
      "  (0, 1190)\t1\n",
      "  (1, 358)\t1\n",
      "  (1, 1070)\t1\n",
      "  (1, 661)\t1\n",
      "  (2, 1070)\t1\n",
      "  (2, 1600)\t1\n",
      "  (2, 1612)\t1\n",
      "  (2, 856)\t1\n",
      "  (2, 1048)\t1\n",
      "  (3, 930)\t1\n",
      "  (3, 1540)\t1\n",
      "  (3, 877)\t1\n",
      "  (3, 91)\t1\n",
      "  (3, 758)\t1\n",
      "  (3, 1344)\t1\n",
      "  (3, 1533)\t1\n",
      "  (3, 1301)\t1\n",
      "  (4, 1413)\t1\n",
      "  (4, 995)\t1\n",
      "  (4, 674)\t1\n",
      "  (4, 1234)\t1\n",
      "  (5, 645)\t1\n",
      "  (5, 29)\t1\n",
      "  :\t:\n",
      "  (995, 869)\t1\n",
      "  (996, 660)\t1\n",
      "  (996, 41)\t1\n",
      "  (996, 824)\t1\n",
      "  (997, 1070)\t2\n",
      "  (997, 1112)\t1\n",
      "  (997, 804)\t1\n",
      "  (998, 856)\t1\n",
      "  (998, 1631)\t1\n",
      "  (998, 1621)\t1\n",
      "  (998, 1686)\t1\n",
      "  (998, 533)\t1\n",
      "  (998, 1581)\t1\n",
      "  (998, 1063)\t1\n",
      "  (999, 1631)\t1\n",
      "  (999, 1645)\t1\n",
      "  (999, 1378)\t1\n",
      "  (999, 246)\t1\n",
      "  (999, 897)\t1\n",
      "  (999, 176)\t1\n",
      "  (999, 701)\t1\n",
      "  (999, 1755)\t1\n",
      "  (999, 1222)\t1\n",
      "  (999, 1809)\t1\n",
      "  (999, 463)\t1\n",
      "In matrix X1 : [[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n",
      "prediction : [1]\n",
      "predict_probs : [[0.17998144 0.82001856]]\n"
     ]
    }
   ],
   "source": [
    "# importing modules\n",
    "import pandas as pd\n",
    "import re\n",
    "from sklearn.feature_extraction.text import ENGLISH_STOP_WORDS\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# load Dataset\n",
    "df= pd.read_csv(\"D:/dataset/sentiment/Restaurant_Reviews.txt\", sep=\"\\t\")\n",
    "\n",
    "# define Feature and Target\n",
    "corpus = df['Review'].tolist()\n",
    "target = df['Liked'].tolist()\n",
    "\n",
    "# converting Text into Lower Order\n",
    "corpus1= list(map(str.lower, corpus))\n",
    "\n",
    "# remove punctutations (symbols like ..., ,)\n",
    "def removePunc(doc):\n",
    "    newdoc = re.sub('[^ a-zA-Z\\s]', '', doc)\n",
    "    return newdoc\n",
    "\n",
    "text = \"Wow... Loved this place.\"\n",
    "cleaned_text = removePunc(text)\n",
    "print(\"After removing Punctutaions :\",cleaned_text)\n",
    "\n",
    "corpus2 = list(map(removePunc, corpus1))\n",
    "\n",
    "#Step-3 remmove stopwords(words having no sentiment) like it, is, was, did, has, have.\n",
    "print(\"Lentgh of English_stop_Words :\", len(ENGLISH_STOP_WORDS))\n",
    "ENGLISH_STOP_WORDS\n",
    "\n",
    "spwords = list(ENGLISH_STOP_WORDS)\n",
    "spwords.remove(\"not\")\n",
    "\n",
    "def removespwords(doc):\n",
    "    wordslist= doc.split()\n",
    "    newdoc=\"\"\n",
    "    for word in wordslist:\n",
    "        if word not in spwords:\n",
    "            newdoc= newdoc+word+\" \"\n",
    "    return newdoc\n",
    "\n",
    "removespwords(\"Not tasty and the texture was just nasty.\t\")\n",
    "\n",
    "corpus3 = list(map(removespwords, corpus2))\n",
    "\n",
    "#Step-4 extract features(each unique is a feature)\n",
    "cv= CountVectorizer()\n",
    "X= cv.fit_transform(corpus3)\n",
    "cv.get_feature_names_out()\n",
    "print(\"get_feature_names_out :\",cv.get_feature_names_out())\n",
    "print(\"The value of X :\",X)\n",
    "X1=X.toarray()\n",
    "print(\"In matrix X1 :\",X1)\n",
    "\n",
    "model= LogisticRegression()\n",
    "model.fit(X, target)\n",
    "print(\"prediction :\",model.predict(cv.transform(['Wow... Loved this place.'])))\n",
    "print(\"predict_probs :\",model.predict_proba(sample4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a3e87536",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter sentiment: place is good but food not\n",
      "Negative Review\n",
      "predict_probs : [[0.60471169 0.39528831]]\n"
     ]
    }
   ],
   "source": [
    "# prediction\n",
    "\n",
    "sample= input('Enter sentiment: ')\n",
    "sample1= sample.lower()\n",
    "sample2= removePunc(sample1)\n",
    "sample3= removespwords(sample2)\n",
    "# print(sample3)\n",
    "\n",
    "sample4= cv.transform([sample3])\n",
    "review= model.predict(sample4)\n",
    "if review==1:\n",
    "    print(\"Postive Review\")\n",
    "else:\n",
    "    print(\"Negative Review\")\n",
    "    \n",
    "print(\"predict_probs :\",model.predict_proba(sample4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "88ccf6de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction : [1]\n",
      "predict_probs : [[0.71 0.29]]\n"
     ]
    }
   ],
   "source": [
    "model= RandomForestClassifier()\n",
    "model.fit(X, target)\n",
    "print(\"prediction :\",model.predict(cv.transform(['Wow... Loved this place.'])))\n",
    "print(\"predict_probs :\",model.predict_proba(sample4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "24b8e4f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CountVectroizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acca9e82",
   "metadata": {},
   "source": [
    "# Whole code using 'def'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db3212ab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
